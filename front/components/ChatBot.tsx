"use client";

import { useState, useRef, useEffect } from "react";
import { Send, AlertTriangle, Mic, Volume2, Square, VolumeX } from "lucide-react";
import { sendChatMessage, type ChatMessage, type OnboardingData } from "../lib/api";
import { Button } from "./ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "./ui/card";
import { Textarea } from "./ui/textarea";
import { Alert, AlertDescription, AlertTitle } from "./ui/alert";
import { Badge } from "./ui/badge";
import { cn } from "@/lib/utils";

interface ChatBotProps {
  userId?: string;
  onEmergencyDetected?: (riskLevel: "medium" | "high" | "critical") => void;
  onboardingData?: OnboardingData | null;
}

// SpeechRecognition íƒ€ì… ì •ì˜
declare global {
  interface Window {
    SpeechRecognition: unknown;
    webkitSpeechRecognition: unknown;
  }
}

const ChatBot = ({ userId, onEmergencyDetected, onboardingData }: ChatBotProps) => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [input, setInput] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const [riskLevel, setRiskLevel] = useState<"low" | "medium" | "high" | "critical" | null>(null);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [hasGreeted, setHasGreeted] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLTextAreaElement>(null);
  const recognitionRef = useRef<unknown>(null);
  const voicesRef = useRef<SpeechSynthesisVoice[]>([]);
  const currentUtteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const shouldSpeakGreetingRef = useRef(false);
  const voicesLoadedRef = useRef(false);

  // TTS ìŒì„± ëª©ë¡ ë¡œë“œ
  useEffect(() => {
    const loadVoices = () => {
      if (typeof window !== "undefined" && "speechSynthesis" in window) {
        const voices = window.speechSynthesis.getVoices();
        if (voices.length > 0) {
          voicesRef.current = voices;
          voicesLoadedRef.current = true;
          console.log("ğŸ”Š Available voices:", voices.length);
          console.log(
            "ğŸ‡°ğŸ‡· Korean voices:",
            voices.filter((v) => v.lang.includes("ko") || v.lang.includes("KR"))
          );
        }
      }
    };

    // ì¦‰ì‹œ ë¡œë“œ ì‹œë„
    loadVoices();

    if (typeof window !== "undefined" && "speechSynthesis" in window) {
      // ìŒì„± ëª©ë¡ì´ ë¡œë“œë˜ë©´ ë‹¤ì‹œ ì‹œë„
      window.speechSynthesis.onvoiceschanged = loadVoices;

      // ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œëŠ” onvoiceschangedê°€ í˜¸ì¶œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
      // ì¶”ê°€ë¡œ ì‹œë„
      const checkInterval = setInterval(() => {
        if (!voicesLoadedRef.current) {
          loadVoices();
        } else {
          clearInterval(checkInterval);
        }
      }, 100);

      // ìµœëŒ€ 3ì´ˆ í›„ì—ëŠ” interval ì •ë¦¬
      setTimeout(() => clearInterval(checkInterval), 3000);
    }

    return () => {
      if (typeof window !== "undefined" && "speechSynthesis" in window) {
        window.speechSynthesis.onvoiceschanged = null;
      }
    };
  }, []);

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  useEffect(() => {
    if (typeof window !== "undefined") {
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

      if (SpeechRecognition) {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        recognitionRef.current = new SpeechRecognition() as any;

        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const recognition = recognitionRef.current as any;
        recognition.lang = "ko-KR";
        recognition.continuous = true;
        recognition.interimResults = true;

        recognition.onstart = () => setIsListening(true);
        recognition.onend = () => setIsListening(false);
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        recognition.onresult = (event: any) => {
          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
              setInput((prev) => prev + transcript + " ");
            }
          }
        };
      }
    }
  }, []);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // ì˜¨ë³´ë”© ì™„ë£Œ í›„ ìë™ ì¸ì‚¬
  useEffect(() => {
    if (onboardingData && !hasGreeted && messages.length === 0) {
      const greetingMessage: ChatMessage = {
        role: "assistant",
        content: `ì•ˆë…•í•˜ì„¸ìš”, ${onboardingData.name}ë‹˜! ğŸ‘‹\n\nì €ëŠ” MindMateì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì •ì‹ ê±´ê°•ì„ í•¨ê»˜ ì¼€ì–´í•´ë“œë¦´ê²Œìš”.\n\nì˜¤ëŠ˜ ì–´ë–¤í•˜ë£¨ë¥¼ ë³´ë‚´ì…¨ì–´ìš”? í•­ìƒ Mateì—ê²Œ í¸í•˜ê²Œ ì–˜ê¸°í•´ì£¼ì„¸ìš”. ì œê°€ ì—¬ê¸° ìˆìœ¼ë‹ˆê¹Œìš”! ğŸ˜Š`,
      };
      setMessages([greetingMessage]);
      setHasGreeted(true);
      shouldSpeakGreetingRef.current = true;
    }
  }, [onboardingData, messages.length, hasGreeted]);

  // ì¸ì‚¬ ë©”ì‹œì§€ê°€ ì¶”ê°€ë˜ë©´ ìŒì„±ìœ¼ë¡œ ì½ì–´ì£¼ê¸°
  useEffect(() => {
    if (shouldSpeakGreetingRef.current && messages.length > 0 && messages[0]?.role === "assistant") {
      shouldSpeakGreetingRef.current = false;
      const timer = setTimeout(() => {
        handleSpeak(messages[0].content);
      }, 500);
      return () => clearTimeout(timer);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [messages]);

  // ìŒì„± ì…ë ¥ ì‹œì‘/ì¤‘ì§€
  const handleVoiceInput = () => {
    if (!recognitionRef.current) return;

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const recognition = recognitionRef.current as any;

    if (isListening) {
      recognition.stop();
    } else {
      setInput("");
      recognition.start();
    }
  };

  // TTS ì¤‘ì§€
  const stopSpeaking = async (): Promise<void> => {
    return new Promise((resolve) => {
      if (window.speechSynthesis.speaking || window.speechSynthesis.pending) {
        window.speechSynthesis.cancel();
        setIsSpeaking(false);
        currentUtteranceRef.current = null;
        console.log("ğŸ›‘ Speech stopped");
        // cancel í›„ ì™„ì „íˆ ì •ë¦¬ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        setTimeout(() => resolve(), 100);
      } else {
        resolve();
      }
    });
  };

  // ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°
  const cleanTextForTTS = (text: string): string => {
    // ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±° (ë” í¬ê´„ì ì¸ íŒ¨í„´)
    const cleaned = text
      // ì´ëª¨ì§€ ë²”ìœ„ ì œê±°
      .replace(/[\u{1F300}-\u{1F9FF}]/gu, "") // ê¸°ë³¸ ì´ëª¨ì§€
      .replace(/[\u{2600}-\u{26FF}]/gu, "") // ê¸°íƒ€ ê¸°í˜¸
      .replace(/[\u{2700}-\u{27BF}]/gu, "") // Dingbats
      .replace(/[\u{1F600}-\u{1F64F}]/gu, "") // ê°ì • ì´ëª¨ì§€
      .replace(/[\u{1F680}-\u{1F6FF}]/gu, "") // êµí†µ ë° ì§€ë„
      .replace(/[\u{1F1E0}-\u{1F1FF}]/gu, "") // êµ­ê¸°
      .replace(/[\u{1F900}-\u{1F9FF}]/gu, "") // ë³´ì¡° ì´ëª¨ì§€
      .replace(/[\u{1FA00}-\u{1FA6F}]/gu, "") // ì²´ìŠ¤ ê¸°í˜¸
      .replace(/[\u{1FA70}-\u{1FAFF}]/gu, "") // í™•ì¥ ê¸°í˜¸
      // ì¶”ê°€ ì´ëª¨ì§€ ë²”ìœ„
      .replace(/[\u{FE00}-\u{FE0F}]/gu, "") // Variation Selectors
      .replace(/[\u{200D}]/gu, "") // Zero Width Joiner
      .replace(/[\u{200C}-\u{200D}]/gu, "") // Zero Width Non-Joiner
      // ì—°ì†ëœ ê³µë°± ì •ë¦¬
      .replace(/\s+/g, " ")
      .trim();

    if (text !== cleaned) {
      console.log(`ğŸ§¹ Cleaned text: "${text.substring(0, 30)}..." â†’ "${cleaned.substring(0, 30)}..."`);
    }

    return cleaned;
  };

  // ìŒì„±ì´ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ” í—¬í¼ í•¨ìˆ˜
  const waitForVoices = (): Promise<SpeechSynthesisVoice[]> => {
    return new Promise((resolve) => {
      if (voicesLoadedRef.current && voicesRef.current.length > 0) {
        resolve(voicesRef.current);
        return;
      }

      // ìŒì„±ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
      if (typeof window !== "undefined" && "speechSynthesis" in window) {
        const voices = window.speechSynthesis.getVoices();
        if (voices.length > 0) {
          voicesRef.current = voices;
          voicesLoadedRef.current = true;
          resolve(voices);
          return;
        }
      }

      // ìŒì„±ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
      let attempts = 0;
      const maxAttempts = 30; // ìµœëŒ€ 3ì´ˆ ëŒ€ê¸°

      const checkVoices = setInterval(() => {
        attempts++;
        if (typeof window !== "undefined" && "speechSynthesis" in window) {
          const voices = window.speechSynthesis.getVoices();
          if (voices.length > 0) {
            voicesRef.current = voices;
            voicesLoadedRef.current = true;
            clearInterval(checkVoices);
            resolve(voices);
            return;
          }
        }

        if (attempts >= maxAttempts) {
          clearInterval(checkVoices);
          // íƒ€ì„ì•„ì›ƒì´ì–´ë„ í˜„ì¬ ìˆëŠ” ìŒì„± ë°˜í™˜
          resolve(voicesRef.current);
        }
      }, 100);
    });
  };

  // TTS (í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜) - í–¥ìƒëœ ë¸Œë¼ìš°ì € Web Speech API
  const handleSpeak = async (text: string) => {
    try {
      if (!("speechSynthesis" in window)) {
        console.warn("âŒ TTS not supported in this browser");
        return;
      }

      // ì´ëª¨ì§€ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬
      const cleanedText = cleanTextForTTS(text);
      if (!cleanedText || cleanedText.length === 0) {
        console.warn("âš ï¸ Text is empty after cleaning");
        return;
      }

      console.log("ğŸ”Š Starting TTS for text:", cleanedText.substring(0, 50) + "...");

      // ê¸°ì¡´ ìŒì„±ì´ ì¬ìƒ ì¤‘ì´ë©´ ì™„ì „íˆ ì¤‘ë‹¨ë  ë•Œê¹Œì§€ ëŒ€ê¸°
      await stopSpeaking();

      // ìŒì„± ëª©ë¡ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
      const voices = await waitForVoices();
      console.log("ğŸ¤ Total voices available:", voices.length);

      if (voices.length === 0) {
        console.warn("âš ï¸ No voices available, retrying...");
        // ìŒì„±ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ìŒì„±ìœ¼ë¡œ ì‹œë„
        const defaultVoices = window.speechSynthesis.getVoices();
        if (defaultVoices.length > 0) {
          voicesRef.current = defaultVoices;
          voicesLoadedRef.current = true;
        }
      }

      // utterance ìƒì„± ì „ì— speechSynthesis ìƒíƒœ í™•ì¸
      if (window.speechSynthesis.speaking || window.speechSynthesis.pending) {
        console.warn("âš ï¸ Speech synthesis is still busy, waiting...");
        await new Promise((resolve) => setTimeout(resolve, 200));
      }

      const utterance = new SpeechSynthesisUtterance(cleanedText);
      utterance.lang = "ko-KR";
      utterance.rate = 1.0;
      utterance.pitch = 1.0;
      utterance.volume = 1.0; // ìµœëŒ€ ë³¼ë¥¨ìœ¼ë¡œ ì„¤ì •

      // ë³¼ë¥¨ í™•ì¸ ë° ë¡œê·¸
      console.log("ğŸ”Š Utterance settings:", {
        volume: utterance.volume,
        rate: utterance.rate,
        pitch: utterance.pitch,
        lang: utterance.lang,
      });

      if (utterance.volume === 0) {
        console.error("âŒ ERROR: Utterance volume is 0!");
      }

      // í˜„ì¬ utterance ì €ì¥
      currentUtteranceRef.current = utterance;

      // í•œêµ­ì–´ ìŒì„± ì„ íƒ
      const availableVoices = voices.length > 0 ? voices : window.speechSynthesis.getVoices();

      const koreanVoice =
        availableVoices.find((v) => v.lang === "ko-KR") ||
        availableVoices.find((v) => v.lang.startsWith("ko")) ||
        availableVoices.find((v) => v.lang.includes("KR"));

      if (koreanVoice) {
        utterance.voice = koreanVoice;
        console.log(`âœ… Using voice: ${koreanVoice.name} (${koreanVoice.lang})`);
      } else {
        console.log("âš ï¸ No Korean voice found, using default voice");
        // í•œêµ­ì–´ ìŒì„±ì´ ì—†ì–´ë„ ê¸°ë³¸ ìŒì„±ìœ¼ë¡œ ì¬ìƒ
        if (availableVoices.length > 0) {
          utterance.voice = availableVoices[0];
        }
      }

      let startTimeout: NodeJS.Timeout | null = null;
      let statusCheckInterval: NodeJS.Timeout | null = null;

      utterance.onstart = () => {
        if (startTimeout) {
          clearTimeout(startTimeout);
          startTimeout = null;
        }
        setIsSpeaking(true);
        console.log("âœ… Speech started successfully (onstart event fired)");
        console.log("ğŸ”Š Current utterance:", {
          text: utterance.text.substring(0, 30),
          lang: utterance.lang,
          voice: utterance.voice?.name,
          volume: utterance.volume,
          rate: utterance.rate,
          pitch: utterance.pitch,
        });

        // ì‹¤ì œë¡œ ì¬ìƒë˜ê³  ìˆëŠ”ì§€ í™•ì¸
        const checkAfterStart = setInterval(() => {
          if (!window.speechSynthesis.speaking && !window.speechSynthesis.pending) {
            console.warn("âš ï¸ Speech stopped unexpectedly after onstart");
            clearInterval(checkAfterStart);
          }
        }, 200);

        // 5ì´ˆ í›„ interval ì •ë¦¬
        setTimeout(() => clearInterval(checkAfterStart), 5000);
      };

      utterance.onend = () => {
        if (startTimeout) {
          clearTimeout(startTimeout);
          startTimeout = null;
        }
        if (statusCheckInterval) {
          clearInterval(statusCheckInterval);
          statusCheckInterval = null;
        }
        if (currentUtteranceRef.current === utterance) {
          setIsSpeaking(false);
          currentUtteranceRef.current = null;
          console.log("âœ… Speech ended (onend event fired) - This confirms speech actually played!");
          console.log("âœ… If you heard the speech, TTS is working correctly!");
          console.log("âœ… If you did NOT hear the speech, check system/browser volume settings");
        }
      };

      utterance.onerror = (event) => {
        if (startTimeout) {
          clearTimeout(startTimeout);
          startTimeout = null;
        }
        if (statusCheckInterval) {
          clearInterval(statusCheckInterval);
          statusCheckInterval = null;
        }
        if (currentUtteranceRef.current === utterance) {
          setIsSpeaking(false);
          currentUtteranceRef.current = null;
          // "canceled"ëŠ” ì •ìƒì ì¸ ì¤‘ë‹¨ì´ë¯€ë¡œ ë¬´ì‹œ
          // "not-allowed"ëŠ” ë¸Œë¼ìš°ì € ì •ì±…ìƒ ìë™ ì¬ìƒì´ ì°¨ë‹¨ëœ ê²½ìš°
          if (event.error !== "canceled" && event.error !== "not-allowed") {
            console.error("âŒ Speech error:", event.error, event);
          } else if (event.error === "not-allowed") {
            console.log("ğŸ”‡ Speech blocked by browser policy (auto-play not allowed)");
          }
        }
      };

      // ì¬ìƒ ì‹œë„ - utterance ì„¤ì • í›„ ì•½ê°„ì˜ ì§€ì—°ì„ ë‘ê³  í˜¸ì¶œ
      try {
        // Chrome/Edgeì—ì„œ ì†ì„± ì„¤ì • í›„ ë°”ë¡œ í˜¸ì¶œí•˜ë©´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
        await new Promise((resolve) => setTimeout(resolve, 50));

        console.log("ğŸ¯ Calling speechSynthesis.speak()");
        console.log("ğŸ“Š SpeechSynthesis state:", {
          speaking: window.speechSynthesis.speaking,
          pending: window.speechSynthesis.pending,
          paused: window.speechSynthesis.paused,
        });

        // speak() í˜¸ì¶œ ì „ì— ì´ì „ utterance ì •ë¦¬
        if (window.speechSynthesis.speaking || window.speechSynthesis.pending) {
          window.speechSynthesis.cancel();
          await new Promise((resolve) => setTimeout(resolve, 50));
        }

        window.speechSynthesis.speak(utterance);

        // speak() í˜¸ì¶œ ì§í›„ ìƒíƒœ í™•ì¸ ë° í•„ìš”ì‹œ resume
        setTimeout(() => {
          if (window.speechSynthesis.paused) {
            console.log("ğŸ”„ Speech is paused, trying to resume...");
            try {
              window.speechSynthesis.resume();
            } catch (e) {
              console.warn("âš ï¸ Resume failed:", e);
            }
          }
        }, 50);

        // speak() í˜¸ì¶œ í›„ ì¦‰ì‹œ ìƒíƒœ í™•ì¸
        setTimeout(() => {
          const isActive = window.speechSynthesis.speaking || window.speechSynthesis.pending;
          console.log("ğŸ“Š After speak() call:", {
            speaking: window.speechSynthesis.speaking,
            pending: window.speechSynthesis.pending,
            isActive,
          });

          if (!isActive && currentUtteranceRef.current === utterance) {
            console.warn("âš ï¸ Speech did not enter active state immediately");
          } else if (isActive) {
            // speakingì´ trueì¸ë° onstartê°€ ì•„ì§ ë°œìƒí•˜ì§€ ì•Šì•˜ë‹¤ë©´ ê²½ê³ 
            console.log("â³ Speaking state is true, waiting for onstart event...");

            // onstartê°€ 500ms ë‚´ì— ë°œìƒí•˜ì§€ ì•Šìœ¼ë©´ ìƒíƒœ í™•ì¸ ë¡œì§ì´ ëŒ€ì‹  ì²˜ë¦¬í•˜ë„ë¡ í•¨
            // (statusCheckIntervalì´ consecutiveActiveChecksë¥¼ í†µí•´ ì²˜ë¦¬)
            setTimeout(() => {
              if (currentUtteranceRef.current === utterance && !isSpeaking) {
                const actuallySpeaking = window.speechSynthesis.speaking || window.speechSynthesis.pending;

                if (!actuallySpeaking) {
                  console.warn("âš ï¸ WARNING: speaking became false before onstart fired!");
                  console.warn("âš ï¸ Retrying immediately...");
                  // ì¦‰ì‹œ ì¬ì‹œë„
                  window.speechSynthesis.cancel();
                  setTimeout(() => {
                    window.speechSynthesis.speak(utterance);
                    console.log("ğŸ”„ Immediate retry: speak() called again");
                  }, 100);
                } else {
                  // speakingì€ trueì¸ë° onstartê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ - ìƒíƒœ í™•ì¸ ë¡œì§ì´ ì²˜ë¦¬í•¨
                  console.log("â³ onstart event not fired, but speech appears active");
                  console.log("â³ Status check interval will handle this case");
                  console.log("ğŸ’¡ This is a known browser bug where onstart doesn't fire");
                  console.log("ğŸ’¡ The speech might still be playing - check your volume!");
                }
              }
            }, 500);
          }
        }, 100);

        // ì£¼ê¸°ì ìœ¼ë¡œ ì¬ìƒ ìƒíƒœ í™•ì¸ ë° onstart ëŒ€ì²´ ë¡œì§
        let consecutiveActiveChecks = 0;
        let hasDetectedStart = false;

        statusCheckInterval = setInterval(() => {
          const isActive = window.speechSynthesis.speaking || window.speechSynthesis.pending;
          const currentUtterance = currentUtteranceRef.current;

          if (isActive && currentUtterance === utterance) {
            consecutiveActiveChecks++;

            // 900ms ì´ìƒ active ìƒíƒœì´ë©´ (3ë²ˆ * 300ms) ì¬ìƒ ì¤‘ìœ¼ë¡œ ê°„ì£¼
            if (consecutiveActiveChecks >= 3 && !hasDetectedStart) {
              console.warn("âš ï¸ onstart event did not fire, but speech appears to be active");
              console.log("âœ… Assuming speech started (workaround for browser bug)");
              console.log("ğŸ”Š If you cannot hear the speech, please check:");
              console.log("   1. System volume is not muted");
              console.log("   2. Browser tab is not muted (check tab icon)");
              console.log("   3. macOS System Settings > Sound > Output device");
              console.log(
                "   4. Try a shorter test: console.log('Test'); new SpeechSynthesisUtterance('í…ŒìŠ¤íŠ¸').onstart=()=>console.log('Playing'); window.speechSynthesis.speak(new SpeechSynthesisUtterance('í…ŒìŠ¤íŠ¸'));"
              );
              setIsSpeaking(true);
              hasDetectedStart = true;

              // onstartê°€ ë°œìƒí–ˆë‹¤ê³  ê°„ì£¼í•˜ê³  ì²˜ë¦¬
              if (startTimeout) {
                clearTimeout(startTimeout);
                startTimeout = null;
              }
            } else if (hasDetectedStart) {
              // ì´ë¯¸ ì¬ìƒ ì¤‘ìœ¼ë¡œ ê°ì§€ë¨ - onend ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ëŠ”ì§€ ì¶”ì 
              if (consecutiveActiveChecks % 10 === 0) {
                // 3ì´ˆë§ˆë‹¤ ìƒíƒœ ë¡œê·¸ (ë„ˆë¬´ ë§ì´ ì¶œë ¥í•˜ì§€ ì•Šê¸° ìœ„í•´)
                const duration = (consecutiveActiveChecks * 300) / 1000;
                console.log(`â³ Still speaking... (${duration.toFixed(1)}s elapsed)`);

                // 30ì´ˆ ì´ìƒ ì¬ìƒ ì¤‘ì´ë©´ ì´ìƒí•œ ìƒí™© (ë³´í†µ ê·¸ë ‡ê²Œ ì˜¤ë˜ ê±¸ë¦¬ì§€ ì•ŠìŒ)
                if (duration > 30) {
                  console.warn("âš ï¸ Speech has been active for over 30 seconds - this is unusual");
                  console.warn("âš ï¸ The speech might not actually be playing");
                }
              }
            }
          } else if (currentUtterance === utterance) {
            // activeê°€ ì•„ë‹ˆê±°ë‚˜ ë‹¤ë¥¸ utteranceë¡œ ë³€ê²½ë¨
            consecutiveActiveChecks = 0;

            if (hasDetectedStart && !isActive) {
              // ì¬ìƒì´ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ë³´ì„
              setIsSpeaking(false);
              if (currentUtterance === utterance) {
                currentUtteranceRef.current = null;
              }
              console.log("âœ… Speech stopped (detected via status check)");
              hasDetectedStart = false;

              if (statusCheckInterval) {
                clearInterval(statusCheckInterval);
                statusCheckInterval = null;
              }
            }
          }
        }, 300); // 300msë§ˆë‹¤ í™•ì¸ (ë” ë¹ ë¥¸ ê°ì§€)

        // onstartê°€ 1ì´ˆ ë‚´ì— ë°œìƒí•˜ì§€ ì•Šìœ¼ë©´ ì¬ì‹œë„
        startTimeout = setTimeout(() => {
          if (statusCheckInterval) {
            clearInterval(statusCheckInterval);
            statusCheckInterval = null;
          }
          if (currentUtteranceRef.current === utterance) {
            const isActuallySpeaking = window.speechSynthesis.speaking || window.speechSynthesis.pending;
            if (!isActuallySpeaking) {
              console.warn("âš ï¸ Speech did not start after 1 second, retrying...");
              window.speechSynthesis.cancel();
              setTimeout(() => {
                try {
                  const retryUtterance = new SpeechSynthesisUtterance(cleanedText);
                  retryUtterance.lang = utterance.lang;
                  retryUtterance.rate = utterance.rate;
                  retryUtterance.pitch = utterance.pitch;
                  retryUtterance.volume = utterance.volume;
                  retryUtterance.voice = utterance.voice;

                  retryUtterance.onstart = () => {
                    setIsSpeaking(true);
                    console.log("âœ… Speech started on retry");
                  };
                  retryUtterance.onend = () => {
                    setIsSpeaking(false);
                    currentUtteranceRef.current = null;
                    console.log("âœ… Speech ended on retry");
                  };
                  retryUtterance.onerror = (e) => {
                    setIsSpeaking(false);
                    currentUtteranceRef.current = null;
                    console.error("âŒ Speech error on retry:", e.error);
                  };

                  currentUtteranceRef.current = retryUtterance;
                  // ì¬ì‹œë„ë„ ì§€ì—° í›„ í˜¸ì¶œ
                  setTimeout(() => {
                    window.speechSynthesis.speak(retryUtterance);
                    console.log("ğŸ”„ Retry speak() called");
                  }, 100);
                } catch (retryError) {
                  console.error("âŒ Retry failed:", retryError);
                }
              }, 200);
            }
          }
        }, 1000);
      } catch (error) {
        setIsSpeaking(false);
        currentUtteranceRef.current = null;
        console.error("âŒ Failed to speak:", error);
      }
    } catch (error) {
      setIsSpeaking(false);
      currentUtteranceRef.current = null;
      console.error("âŒ TTS error:", error);
    }
  };

  const handleSend = async () => {
    if (!input.trim() || isLoading) return;

    const userMessage: ChatMessage = {
      role: "user",
      content: input.trim(),
    };

    setMessages((prev) => [...prev, userMessage]);
    setInput("");
    setIsLoading(true);
    setRiskLevel(null);

    try {
      const response = await sendChatMessage({
        message: userMessage.content,
        conversation_history: messages,
        user_id: userId,
      });

      const assistantMessage: ChatMessage = {
        role: "assistant",
        content: response.message,
      };

      setMessages((prev) => [...prev, assistantMessage]);
      setRiskLevel(response.risk_level || null);

      // ìœ„ê¸° ìƒí™© ê°ì§€ ì‹œ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ì— ì•Œë¦¼
      if (response.risk_level && response.risk_level !== "low" && onEmergencyDetected) {
        onEmergencyDetected(response.risk_level);
      }

      // ìë™ ìŒì„± ì¶œë ¥
      handleSpeak(response.message);
    } catch (error) {
      console.error("ì±„íŒ… ì˜¤ë¥˜:", error);

      let errorMessage: ChatMessage;

      // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ í™•ì¸
      if (error instanceof Error) {
        if (error.message.includes("Network Error") || error.message.includes("ERR_NETWORK")) {
          errorMessage = {
            role: "assistant",
            content:
              "âš ï¸ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n" +
              "í•´ê²° ë°©ë²•:\n" +
              "1. ìƒˆ í„°ë¯¸ë„ì„ ì—´ê³ \n" +
              "2. cd /Users/dowonkim/Desktop/code/school/agent\n" +
              "3. uv run python main.py\n\n" +
              "FastAPI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
          };
        } else {
          errorMessage = {
            role: "assistant",
            content: `ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`,
          };
        }
      } else {
        errorMessage = {
          role: "assistant",
          content: "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        };
      }

      setMessages((prev) => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
      inputRef.current?.focus();
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  const getRiskLevelBadge = () => {
    if (!riskLevel || riskLevel === "low") return null;

    const variants = {
      critical: "destructive" as const,
      high: "destructive" as const,
      medium: "default" as const,
    };

    const labels = {
      critical: "ê¸´ê¸‰",
      high: "ì£¼ì˜",
      medium: "ê´€ì°°",
    };

    return (
      <Badge variant={variants[riskLevel] || "default"} className="ml-2">
        {labels[riskLevel]}
      </Badge>
    );
  };

  return (
    <Card className="flex flex-col h-full max-h-[600px] w-full">
      <CardHeader>
        <div className="flex items-center justify-between">
          <div>
            <CardTitle>MindMate AI Mate</CardTitle>
            <CardDescription>ì–¸ì œë“ ì§€ í¸í•˜ê²Œ ëŒ€í™”í•´ì£¼ì„¸ìš”</CardDescription>
          </div>
          {riskLevel && riskLevel !== "low" && getRiskLevelBadge()}
        </div>
      </CardHeader>

      {riskLevel && riskLevel !== "low" && (
        <div className="px-6 pb-4">
          <Alert
            variant={riskLevel === "critical" ? "destructive" : "default"}
            className={cn(
              riskLevel === "critical" && "border-red-600 bg-red-50 shadow-lg",
              riskLevel === "high" && "border-orange-500 bg-orange-50",
              riskLevel === "medium" && "border-yellow-500 bg-yellow-50"
            )}
          >
            <AlertTriangle className="h-4 w-4" />
            <AlertTitle>
              {riskLevel === "critical" && "ğŸš¨ ê¸´ê¸‰ ë„ì›€ í•„ìš”"}
              {riskLevel === "high" && "âš ï¸ ì£¼ì˜ í•„ìš”"}
              {riskLevel === "medium" && "âš ï¸ ê´€ì°° í•„ìš”"}
            </AlertTitle>
            <AlertDescription
              className={cn(
                riskLevel === "critical" && "text-red-900 font-semibold",
                riskLevel === "high" && "text-orange-900",
                riskLevel === "medium" && "text-yellow-900"
              )}
            >
              {riskLevel === "critical" && (
                <div className="space-y-2">
                  <p>ë‹¹ì‹ ì˜ ì•ˆì „ì´ ìš°ë¦¬ì˜ ìµœìš°ì„  ê´€ì‹¬ì‚¬ì…ë‹ˆë‹¤.</p>
                  <p className="font-bold">ì¦‰ì‹œ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”:</p>
                  <ul className="list-disc list-inside text-sm font-bold">
                    <li>
                      ì •ì‹ ê±´ê°•ìœ„ê¸°ìƒë‹´ì „í™”: <span className="text-red-700">1393</span> (24ì‹œê°„)
                    </li>
                    <li>
                      ì‘ê¸‰ì‹¤: <span className="text-red-700">119</span>
                    </li>
                    <li>
                      ìì‚´ì˜ˆë°©ìƒë‹´: <span className="text-red-700">1588-9191</span>
                    </li>
                  </ul>
                </div>
              )}
              {riskLevel === "high" && (
                <p>
                  ì „ë¬¸ê°€ì˜ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ì‹ ê±´ê°•ìœ„ê¸°ìƒë‹´ì „í™”(1393) ë˜ëŠ” ì‘ê¸‰ì‹¤(119)ì— ì—°ë½í•˜ëŠ” ê²ƒì„
                  ê¶Œì¥í•©ë‹ˆë‹¤.
                </p>
              )}
              {riskLevel === "medium" && <p>ìƒíƒœë¥¼ ìì„¸íˆ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì‹œ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”.</p>}
            </AlertDescription>
          </Alert>
        </div>
      )}

      <CardContent className="flex-1 flex flex-col overflow-hidden p-6 pt-0">
        <div className="flex-1 overflow-y-auto space-y-4 mb-4 pr-2">
          {messages.length === 0 && (
            <div className="text-center text-muted-foreground py-8">
              <p className="mb-2">ì•ˆë…•í•˜ì„¸ìš”! MindMate AI Mateì…ë‹ˆë‹¤.</p>
              <p>ì–´ë–¤ ì´ì•¼ê¸°ë“  í¸í•˜ê²Œ ë‚˜ëˆ ì£¼ì„¸ìš”.</p>
            </div>
          )}

          {messages.map((message, index) => (
            <div
              key={index}
              className={cn("flex items-end gap-2", message.role === "user" ? "justify-end" : "justify-start")}
            >
              <div
                className={cn(
                  "max-w-[80%] rounded-lg px-4 py-2 text-sm",
                  message.role === "user" ? "bg-primary text-primary-foreground" : "bg-muted text-muted-foreground"
                )}
              >
                <p className="whitespace-pre-wrap">{message.content}</p>
              </div>
              {message.role === "assistant" && (
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={() => (isSpeaking ? stopSpeaking() : handleSpeak(message.content))}
                  className="h-8 w-8 p-0"
                  title={isSpeaking ? "ìŒì„± ì¤‘ì§€" : "ìŒì„± ì¬ìƒ"}
                >
                  {isSpeaking ? <VolumeX className="h-4 w-4" /> : <Volume2 className="h-4 w-4" />}
                </Button>
              )}
            </div>
          ))}

          {isLoading && (
            <div className="flex justify-start">
              <div className="bg-muted rounded-lg px-4 py-2">
                <div className="flex gap-1">
                  <span className="w-2 h-2 bg-muted-foreground rounded-full animate-bounce" />
                  <span
                    className="w-2 h-2 bg-muted-foreground rounded-full animate-bounce"
                    style={{ animationDelay: "0.2s" }}
                  />
                  <span
                    className="w-2 h-2 bg-muted-foreground rounded-full animate-bounce"
                    style={{ animationDelay: "0.4s" }}
                  />
                </div>
              </div>
            </div>
          )}

          <div ref={messagesEndRef} />
        </div>

        <div className="flex gap-2">
          <Textarea
            ref={inputRef}
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={handleKeyDown}
            placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë§ˆì´í¬ë¥¼ í´ë¦­í•˜ì„¸ìš”..."
            rows={2}
            disabled={isLoading || isListening}
            tabIndex={0}
            aria-label="ì±„íŒ… ë©”ì‹œì§€ ì…ë ¥"
            className="resize-none"
          />
          <div className="flex flex-col gap-2">
            <Button
              onClick={handleVoiceInput}
              disabled={isLoading || isSpeaking}
              variant={isListening ? "destructive" : "outline"}
              size="icon"
              className="shrink-0"
              tabIndex={0}
              aria-label={isListening ? "ìŒì„± ì¸ì‹ ì¤‘ì§€" : "ìŒì„± ì…ë ¥"}
            >
              {isListening ? <Square className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
            </Button>
            <Button
              onClick={handleSend}
              disabled={!input.trim() || isLoading || isListening}
              size="icon"
              className="shrink-0"
              tabIndex={0}
              aria-label="ë©”ì‹œì§€ ì „ì†¡"
            >
              <Send className="h-4 w-4" />
            </Button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
};

export default ChatBot;
